
SECCIÓN 1:
*********

Repo del proyecto: https://github.com/vinsguru/spring-webflux-course

Necesidad de WebFlux:

En arquitecturas tradicionales, incluso en microservicios, se ve que se crean múltiples threads
para procesar las peticiones I/O. Sin embargo, estos threads quedan en un estado de "waiting" mientras
esperan la respuesta a los request que han sido enviados. Esto implica un uso de memoria ram muy alto
y recursos desperdiciados en ese "tiempo de espera del response" por una falta de "multitasking".

En el stack reactivo se introduce el término "non-blocking", quiere decir que los threads pueden procesar
una mayor cantidad de requests porque no esperan el response por cada petición. A diferencia de la 
arquitectura tradicional, los threads que están "libres" pueden seguir procesando requests y cuando 
llegue el response lo procesan en paralelo.


Reactive Manifesto -> Reactive Systems

Maintainable    Extensible

        Responsive
            |
  Elastic ----- Resilient
            |
        Message Driven

Responsive: Responder rápido y realizar el trabajo mientras el usuario lo requiera.
            Por ejemplo si el usuario ya cerró el browser el backend no debería seguir procesando.

Resilient: Permanecer responsive a pesar de los fallos. No tiene que caerse todo el sistema por una
           funcionalidad caída.

Elastic: El sistema escala automáticamente de acuerdo a la demanda.

Message Driven: Comunicación non-blocking & async entre sistemas. Se aplica el concepto de 
                Backpressure(si el sistema es lento para procesar los items recibidos se baja
                la carga de emisión).



SECCIÓN 3: Spring WebFlux
*************************

Spring Web corre en Servlet container(async y blocking)
Spring Web Reactive corre en Servlet 3.1, Netty, Undertow

Netty se basa en Thread Groups y tiene un "boss" y otros workers
que son los que procesan las operaciones I/O


webflux-demo

(Videos 16 y 17)
En la clase ReactiveMathController es clave el endpoint table/{input}/stream
porque demuestra dos ventajas de la programacion reactiva:

- Puede entregar el response apenas lo tenga
- Una vez cancelada la subscripción desde el navegador ya no se ejecuta ningún 
  proceso en el backend.

El endpoint que no tiene produces = MediaType.TEXT_EVENT_STREAM_VALUE toma un 
comportamiento por defecto que es realizar un collect de todos los elementos
y transformarlos a json para luego retornarlos. Esto se da por una lógica en
la clase AbstractJackson2Encoder.



SECCIÓN 4: Functional Endpoints
*******************************

Router Config: Para tener los endpoints de una manera funcional
Router Handler: El método que se ejecuta cuando el path funcional es invocado
Streaming Endpoint: tableStreamHandler para que el backend deje de procesar si se cancela la petición 
Functional Endpoints: GET, POST
Exception Handling: Método que maneja las excepciones
Path Based Routing Config: Es como el RequestMapping inicial en el mvc tradicional
Request Predicates: Complementa el RouterFunction con cierta lógica
Assignment: Se usó el manejo de headers


SECCIÓN 5: Webclient
********************

Es un Reactive RestTemplate para hacer peticiones HTTP

StepVerifier: Library Test
- GET Mono
- GET Flux
- GET Flux Streaming Endpoint (Stream emite cuando el item está listo)
- POST request
- String Request Header
- Handling Bad Request
- Exchange vs Retrieve --- exchange = retrieve + additional info(http status code)
- Query Params -- Se vieron tres maneras diferentes de hacerlo
- Setting Auth Token -- Se añadió código en WebClientConfig y en el test de Lec04HeadersTest
- Atrributes -- se usó para setear a different type of credentials at runtime.
  Para probar se debe activar sessionAttrToken en WebClientConfig.
- Assignment: Se usó doble flatmap para enviar valores


SECCIÓN 6: Spring Data Reactive - MongoDB
*****************************************

Se creó el product-service con las dependencias de maven:
- spring reactive web
- spring data reactive mongodb
- embedded mongodb database (testing) (comentar el scope test)
- lombok

File->New->Module from existing source

Se agregó <version>${project.parent.version}</version> en el plugin para evitar el error:
"Plugin 'org.springframework.boot:spring-boot-maven-plugin:' not found"

- BeanUtils.copyProperties para transformar objetos con las propiedades
- Revisar doc sobre mappers & performance: 
  https://www.vinsguru.com/microservices-dto-to-entity-entity-to-dto-mapping-libraries-comparison/

- Se creó una instancia de docker con el comando: docker run -p 27017:27017 -d mongo

(De esta segunda forma sale error)
También se puede crear con el docker-compose.yml y el comando: docker-compose up

version: "3"
services:
  mongo:
    image: mongo
    ports:
      - 27017:27017
    volumes:
      - ./mongo:/data/db  
  mongo-express:
    image: mongo-express
    ports:
      - 8081:8081


Y para acceder al express server ir a localhost:8081


- Se comentó una dependencia de test en pom para que no se conecte a la bd en un ambiente de test.
Sin embargo, a mi eso nunca me funcionó y me conectaba a docker directamente.



SECCIÓN 7: Spring Data R2DBC
****************************

Documentación:
https://docs.spring.io/spring-data/r2dbc/docs/current/reference/html/#reference

Se creó el user-service con las dependencias de maven:
- spring reactive web
- spring data r2dbc
- h2
- lombok

- Se usar org.springframework.data.relational.core.mapping.Table en lugar de Entity(JPA) para mapear la entidad(tabla).

- Se agregó query en el repository

- Doc sobre Transaction Management: https://www.vinsguru.com/spring-data-r2dbc-transaction/

- Drivers R2DBC: https://docs.spring.io/spring-data/r2dbc/docs/current/reference/html/#r2dbc.drivers

- Se agregó "on delete cascade" en el init.sql para que se pudiera borrar el registro luego de haber interactuado en la
  tabla de transactions. También se puede comentar la línea del foreign key para mantener un historial de las transacciones.


- Docker compose file para crear postgre db. El comando es: docker-compose up

version: "3"
services:
  postgres:
    image: postgres
    container_name: postgres
    environment:
      - POSTGRES_USER=vinsguru
      - POSTGRES_PASSWORD=admin
      - POSTGRES_DB=userdb
    volumes:
      - ./docker-volume/db:/var/lib/postgresql/data
    ports:
      - 5432:5432
  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@vinsguru.com
      - PGADMIN_DEFAULT_PASSWORD=admin
    volumes:
      - ./docker-volume/pgadmin:/var/lib/pgadmin
    ports:
      - 9000:80

  Al intentar crear se obtuvo el error: "Error response from daemon: user declined directory sharing ..."
  Para solucionarlo se hizo lo sgte: "Go to docker dashboard -> settings ->Resources -> FileSharing. 
  Add required folder and hit Apply & Restart" (funcionó)

  Ir a http://localhost:9000/ para consola de pgadmin(si me funcionó)
  Darle en register server -> name: userdb, hostname: postgres, username: vinsguru, password: admin

  Salió otro error en el que no se podía levantar la imagen de postgre por eso no se podía dar la conexión
  correctamente. Para ello se ejecutó: docker volume create db_volume y se modificó el yml
  Funcionó bien, se pudo levantar el container de postgre y crear el server en pgadmin

  Nuevo docker-compose.yml:

  version: "3"
  services:
    postgres:
      image: postgres
      container_name: postgres
      environment:
        - POSTGRES_USER=vinsguru
        - POSTGRES_PASSWORD=admin
        - POSTGRES_DB=userdb
      volumes:
        - db_volume:/var/lib/postgresql/data
      ports:
        - 5432:5432
    pgadmin:
      image: dpage/pgadmin4
      container_name: pgadmin
      environment:
        - PGADMIN_DEFAULT_EMAIL=admin@vinsguru.com
        - PGADMIN_DEFAULT_PASSWORD=admin
      volumes:
        - ./docker-volume/pgadmin:/var/lib/pgadmin
      ports:
        - 9000:80
  volumes:
    db_volume:
      external: true

  Ejecutar el siguiente script en query tools:


  CREATE TABLE USERS (
    id serial primary key,
    name varchar(50),
    balance int
  );

  CREATE TABLE USER_TRANSACTION (
    id serial primary key,
    user_id bigint,
    amount int,
    transaction_date timestamp,
    CONSTRAINT fk_user_id
        FOREIGN KEY (user_id)
        REFERENCES users(id)
        on delete cascade
  );

  Modificar el properties y comentar el @Service de DataSetupService
  Probar en postman los servicios y validar en el pgadmin la data creada(funcionó OK)

- para cambiar a postgre se deben comentar las dependencias de h2 y en el spring initializr
  agregar dependencias de R2DBC y postgre driver con explore para copiar las dependencias.


  <dependency>
      <groupId>org.postgresql</groupId>
      <artifactId>postgresql</artifactId>
      <scope>runtime</scope>
    </dependency>
    <dependency>
      <groupId>org.postgresql</groupId>
      <artifactId>r2dbc-postgresql</artifactId>
      <scope>runtime</scope>
    </dependency>

Al final se usó el comando: git update-index --assume-unchanged docker-volume/
para no subir el volumedb creado por docker(no funcionó, se subieron los cambios)

Se usó git rm docker-volume -r (funcionó correctamente)

SECCIÓN 8: Reactive Microservices
*********************************

-Se creó el order-service con las dependencias de maven:
Spring Reactive Web, H2, JPA, Lombok

-Se copiaron los dto's de los otros dos microservicios

-Documentación Dto's in microservices:
https://www.vinsguru.com/microservices-architecture-how-to-share-dto-data-transfer-objects/

- Se hicieron las conexiones a otros microservicios con webclient. Las pruebas salieron bien.

[RESILIENT]
- Handling service unavailability. Se añadieron excepciones para cuando se envía un request incorrecto
y cuando el servicio no está disponible.

- Se simuló una intermitencia con product-service(en el controller productById) y en postman retorna bad request. 
Se agregó retryWhen en OrderFullfilmentService. Las pruebas salieron bien en postman. Se ve que se demora un poco más
cuando detecta la intermitencia pero al final responde bien. 


Resilient Design Patterns:

https://www.vinsguru.com/timeout-pattern/
https://www.vinsguru.com/retry-pattern/
https://www.vinsguru.com/circuit-breaker-pattern/
https://www.vinsguru.com/bulkhead-pattern/

- Se hizo un test haciendo un match de usuarios con productos con Flux.zip, salió bien.










